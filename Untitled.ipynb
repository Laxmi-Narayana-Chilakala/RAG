{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "810ccfa0-2f47-4ef6-ac6b-4e6014a90172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "659bff4e-fbed-40c7-b91a-3092aace0d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=\"sk-GB1RUY7SOFmzuckWQERCT3BlbkFJ9ivkZjXFD6tR7yjAocc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c396319-4e46-45c6-ae46-eeef71c54ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc2e4a95-c69d-4ae4-a017-b30388e02082",
   "metadata": {},
   "outputs": [],
   "source": [
    "Youtube_video=\"https://www.youtube.com/watch?v=cdiD-9MMpb0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db52754b-0abd-4e02-bae5-7e51c4984fe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.2.5-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting langchain_core\n",
      "  Downloading langchain_core-0.2.7-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.30-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.77-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Downloading pydantic-2.7.4-py3-none-any.whl.metadata (109 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (8.3.0)\n",
      "Collecting openai<2.0.0,>=1.26.0 (from langchain_openai)\n",
      "  Downloading openai-1.34.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain_core)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/codespace/.local/lib/python3.10/site-packages (from langchain_core) (24.0)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/codespace/.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (2.4)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.4.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.26.0->langchain_openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.26.0->langchain_openai)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<5,>=4.7 in /home/codespace/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.12.0)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.4 (from pydantic<3,>=1->langchain)\n",
      "  Downloading pydantic_core-2.18.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain_openai)\n",
      "  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m991.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: exceptiongroup>=1.0.2 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain_openai) (1.2.1)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (0.14.0)\n",
      "Downloading langchain-0.2.5-py3-none-any.whl (974 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.1.8-py3-none-any.whl (38 kB)\n",
      "Downloading langchain_core-0.2.7-py3-none-any.whl (315 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.6/315.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n",
      "Downloading langsmith-0.1.77-py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.34.0-py3-none-any.whl (325 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.7.4-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.0/409.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.30-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, regex, pydantic-core, orjson, multidict, jsonpatch, greenlet, frozenlist, distro, async-timeout, annotated-types, yarl, tiktoken, SQLAlchemy, pydantic, aiosignal, openai, langsmith, aiohttp, langchain_core, langchain-text-splitters, langchain_openai, langchain\n",
      "Successfully installed SQLAlchemy-2.0.30 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.7.0 async-timeout-4.0.3 distro-1.9.0 frozenlist-1.4.1 greenlet-3.0.3 jsonpatch-1.33 langchain-0.2.5 langchain-text-splitters-0.2.1 langchain_core-0.2.7 langchain_openai-0.1.8 langsmith-0.1.77 multidict-6.0.5 openai-1.34.0 orjson-3.10.5 pydantic-2.7.4 pydantic-core-2.18.4 regex-2024.5.15 tiktoken-0.7.0 tqdm-4.66.4 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "#!pip install langchain langchain_openai langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bbf363d-3f73-42d4-a0e3-eeb2f1d99821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "model=ChatOpenAI(openai_api_key=OPENAI_API_KEY,model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c82c5e-4e3f-4cf9-a1fd-73a3fdb946b9",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "417d2b6d-5569-4463-ba93-d2ca968491f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Large language models are a type of artificial intelligence that is trained on vast amounts of text data in order to generate human-like text. These models are designed to understand and generate human language in a way that is indistinguishable from how a human might write or speak.\\n\\nThese models are typically built using deep learning techniques, such as transformers, which are able to process and learn from massive amounts of text data. By training on such large datasets, these models are able to generate coherent and contextually appropriate text responses to prompts or questions.\\n\\nLarge language models have a wide range of applications, including natural language processing, machine translation, chatbots, and text generation. They are used in various industries, such as customer service, content creation, and virtual assistants.\\n\\nHowever, there are also concerns about the potential misuse of large language models, such as generating fake news, misinformation, or biased content. Researchers and developers are working on ways to mitigate these risks and ensure that large language models are used responsibly.', response_metadata={'token_usage': {'completion_tokens': 198, 'prompt_tokens': 12, 'total_tokens': 210}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9e92bb38-8d65-46d9-89e5-4ec4fba0048c-0', usage_metadata={'input_tokens': 12, 'output_tokens': 198, 'total_tokens': 210})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Explain Large Language Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05acc764-df47-4f91-90e0-900a426fca07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='2+2=4', response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 11, 'total_tokens': 16}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-eb0d55ca-b2c3-4c4d-bc54-7bc91d2919c7-0', usage_metadata={'input_tokens': 11, 'output_tokens': 5, 'total_tokens': 16})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"2+2?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4feec69-4746-4916-b620-b386e2f7f8a8",
   "metadata": {},
   "source": [
    "#### We are getting output of AIMessage and other extra content, so get only exact text will use parser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457ae77c-f042-41ee-9ea0-f3d0baf0237e",
   "metadata": {},
   "source": [
    "## Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69d36c1b-230e-4ef5-abeb-cd5e6903768d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Large language models are a type of artificial intelligence that is designed to understand and generate human language. These models are trained on vast amounts of text data, such as books, articles, and websites, in order to learn the patterns and structures of language.\\n\\nLarge language models use deep learning techniques, such as neural networks, to process and generate text. These models are able to understand the context of a given text and generate responses that are coherent and relevant to the input.\\n\\nOne of the key features of large language models is their ability to generate human-like text, which can be used for various applications such as language translation, text summarization, and chatbots. These models have been used in a wide range of applications, including virtual assistants like Siri and Alexa, language translation services like Google Translate, and content generation tools for writers and marketers.\\n\\nOverall, large language models have the potential to revolutionize the way we interact with technology and communicate with each other. However, there are also concerns about the ethical implications of these models, such as bias in the data they are trained on and the potential for misuse in generating fake news or misinformation.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser=StrOutputParser()\n",
    "chain=model | parser\n",
    "chain.invoke(\"Explain Large Language Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62ad02a9-c9f2-4632-8433-32d289a4e87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large language models are AI models that are trained on vast amounts of text data in order to understand and generate human-like language. These models typically use deep learning techniques, such as neural networks, to process and analyze the data.\n",
      "\n",
      "These models have the ability to generate text that is coherent and contextually relevant, making them useful for a variety of natural language processing tasks, such as language translation, text summarization, and question answering.\n",
      "\n",
      "One of the most famous examples of a large language model is OpenAI's GPT-3, which has 175 billion parameters and is capable of generating highly realistic and human-like text. These models continue to improve and evolve as more data is fed into them, making them increasingly sophisticated and versatile in their language generation capabilities.\n"
     ]
    }
   ],
   "source": [
    "response=chain.invoke(\"Explain Large Language Models\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32a5d57-101e-45a2-a292-c501876956d5",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87791c65-6854-4875-93e7-88879fb25473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "Answer the question based on the context below. If you can't answer the question, reply \"I don't know\".\n",
      "\n",
      "Context:Lakshmi's sister is NagaSri\n",
      "\n",
      "Question:who is Lakshmi's sister?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template=\"\"\"\n",
    "Answer the question based on the context below. If you can't answer the question, reply \"I don't know\".\n",
    "\n",
    "Context:{context}\n",
    "\n",
    "Question:{question}\n",
    "\"\"\"\n",
    "prompt=ChatPromptTemplate.from_template(template)\n",
    "prompt_template=prompt.format(context=\"Lakshmi's sister is NagaSri\",question=\"who is Lakshmi's sister?\")\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a304c2-d065-47c6-8577-178a3bf4c2b3",
   "metadata": {},
   "source": [
    "### Now will chain the prompt model and the output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12b55f6f-bc46-466b-b2b9-885b89e5c821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NagaSri'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "chain.invoke({\"context\":\"Lakshmi's sister is NagaSri\",\n",
    "              \"question\":\"who is Lakshmi's sister?\"\n",
    "             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1a2eea5-a4d4-4dbf-a277-7c2898fabadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "chain.invoke({\"context\":\"Lakshmi's sister is NagaSri\",\n",
    "              \"question\":\"who is Naveen's sister?\"\n",
    "             })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5f7a3a-acbf-4332-9c65-cbf81475b88b",
   "metadata": {},
   "source": [
    "## Combining Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23edb55-fe84-47c8-aa37-bce82e109e81",
   "metadata": {},
   "source": [
    "### we can combine different chain to make more complex flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "702e9000-f4f2-4f3c-8de5-0d91c800208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_prompt=ChatPromptTemplate.from_template(\"Translate {answer} to {language}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de27179b-9581-4cac-b3e1-afd18cb74f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lakshmi tiene una hermana.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "translation_chain=({\"answer\":chain,\"language\":itemgetter(\"language\")} | translation_prompt | model | parser)\n",
    "translation_chain.invoke({\n",
    "    \"context\":\"Lakshmi's sister is NagaSri. She doesn't have any more sibilings.\",\n",
    "    \"question\":\"How many sisters does Lakshmi have?\",\n",
    "    \"language\":\"Spanish\"}\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6552953f-3fcb-401d-a988-0f0731139329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'లక్ష్మీకి ఒక సోదరి ఉంది, నాగశ్రీ.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "translation_chain=({\"answer\":chain,\"language\":itemgetter(\"language\")} | translation_prompt | model | parser)\n",
    "translation_chain.invoke({\n",
    "    \"context\":\"Lakshmi's sister is NagaSri. She doesn't have any more sibilings.\",\n",
    "    \"question\":\"How many sisters does Lakshmi have?\",\n",
    "    \"language\":\"Telugu\"}\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eee2a10-3aad-4cc6-b092-49d1884b202e",
   "metadata": {},
   "source": [
    "## Transcribing the Youtube Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8223da36-c04e-479d-80e1-24203ec37358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting whisper\n",
      "  Downloading whisper-1.1.10.tar.gz (42 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m433.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from whisper) (1.16.0)\n",
      "Building wheels for collected packages: whisper\n",
      "  Building wheel for whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41120 sha256=5727c2f17693091f5ec6cb75c7008a217200bff7ac804ed79b404d0f43776e96\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/aa/7c/1d/015619716e2facae6631312503baf3c3220e6a9a3508cb14b6\n",
      "Successfully built whisper\n",
      "Installing collected packages: whisper\n",
      "Successfully installed whisper-1.1.10\n"
     ]
    }
   ],
   "source": [
    "#!pip install whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16636122-91ea-4323-a5f5-4e98d933433d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytube\n",
      "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m625.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m863.4 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytube\n",
      "Successfully installed pytube-15.0.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd9cff5b-fcc6-4e40-849d-34ad4abe362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import whisper\n",
    "from pytube import YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad3710ba-de6d-496a-b45c-ff3ff96a6f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setuptools-rust\n",
      "  Downloading setuptools_rust-1.9.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: setuptools>=62.4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from setuptools-rust) (68.2.2)\n",
      "Collecting semantic-version<3,>=2.8.2 (from setuptools-rust)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: tomli>=1.2.1 in /home/codespace/.local/lib/python3.10/site-packages (from setuptools-rust) (2.0.1)\n",
      "Downloading setuptools_rust-1.9.0-py3-none-any.whl (26 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Installing collected packages: semantic-version, setuptools-rust\n",
      "Successfully installed semantic-version-2.10.0 setuptools-rust-1.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install setuptools-rust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9acce14-05af-45c9-bef6-b407624894ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-uuqce_2m\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-uuqce_2m\n",
      "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802826 sha256=919b21c606b812b4a89adac9d83bd17bab9193309d52f90eef2740ff40afe436\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dum3s535/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: openai-whisper\n",
      "Successfully installed openai-whisper-20231117\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab56c4a0-0930-4f1c-ad5d-a4f6f552042d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper in /usr/local/python/3.10.13/lib/python3.10/site-packages (20231117)\n",
      "Collecting numba (from openai-whisper)\n",
      "  Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from openai-whisper) (1.26.4)\n",
      "Requirement already satisfied: torch in /home/codespace/.local/lib/python3.10/site-packages (from openai-whisper) (2.3.0+cpu)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai-whisper) (4.66.4)\n",
      "Collecting more-itertools (from openai-whisper)\n",
      "  Downloading more_itertools-10.3.0-py3-none-any.whl.metadata (36 kB)\n",
      "Requirement already satisfied: tiktoken in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai-whisper) (0.7.0)\n",
      "Collecting triton<3,>=2.0.0 (from openai-whisper)\n",
      "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from triton<3,>=2.0.0->openai-whisper) (3.14.0)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba->openai-whisper)\n",
      "  Downloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/codespace/.local/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/codespace/.local/lib/python3.10/site-packages (from torch->openai-whisper) (4.12.0)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.10/site-packages (from torch->openai-whisper) (1.12.1)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.10/site-packages (from torch->openai-whisper) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from torch->openai-whisper) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.10/site-packages (from torch->openai-whisper) (2024.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->torch->openai-whisper) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
      "Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading more_itertools-10.3.0-py3-none-any.whl (59 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, more-itertools, llvmlite, numba\n",
      "Successfully installed llvmlite-0.43.0 more-itertools-10.3.0 numba-0.60.0 triton-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06db04e2-f4c2-483f-859c-648969483940",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'whisper' has no attribute 'load_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m youtube\u001b[38;5;241m=\u001b[39mYouTube(Youtube_video)\n\u001b[1;32m      3\u001b[0m audio\u001b[38;5;241m=\u001b[39myoutube\u001b[38;5;241m.\u001b[39mstreams\u001b[38;5;241m.\u001b[39mfilter(only_audio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mfirst()\n\u001b[0;32m----> 4\u001b[0m whisper_model\u001b[38;5;241m=\u001b[39m\u001b[43mwhisper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#with tempfile.TemporaryDirectory() as tmpdir\u001b[39;00m\n\u001b[1;32m      6\u001b[0m file\u001b[38;5;241m=\u001b[39maudio\u001b[38;5;241m.\u001b[39mdownload(output_path\u001b[38;5;241m=\u001b[39mcmd)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'whisper' has no attribute 'load_model'"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"transcription.txt\"):\n",
    "    youtube=YouTube(Youtube_video)\n",
    "    audio=youtube.streams.filter(only_audio=True).first()\n",
    "    whisper_model=whisper.load_model(\"base\")\n",
    "    #with tempfile.TemporaryDirectory() as tmpdir\n",
    "    file=audio.download(output_path=cmd)\n",
    "    transcription=whisper_model.transcribe(file,fp16=False)['text'].strip()\n",
    "\n",
    "    with open(\"transcription.txt\",\"w\") as file:\n",
    "        file.write(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c035ee5-9169-4784-b7d5-dde5f8a24ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ffmpeg-python\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting future (from ffmpeg-python)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: future, ffmpeg-python\n",
      "Successfully installed ffmpeg-python-0.2.0 future-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "672efa23-5e20-4e86-8929-6216f75c66d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-1mpkaso6\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-1mpkaso6\n",
      "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numba in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai-whisper==20231117) (0.60.0)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from openai-whisper==20231117) (1.26.4)\n",
      "Requirement already satisfied: torch in /home/codespace/.local/lib/python3.10/site-packages (from openai-whisper==20231117) (2.3.0+cpu)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai-whisper==20231117) (4.66.4)\n",
      "Requirement already satisfied: more-itertools in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai-whisper==20231117) (10.3.0)\n",
      "Requirement already satisfied: tiktoken in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai-whisper==20231117) (0.7.0)\n",
      "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai-whisper==20231117) (2.3.1)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.14.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from numba->openai-whisper==20231117) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tiktoken->openai-whisper==20231117) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/codespace/.local/lib/python3.10/site-packages (from tiktoken->openai-whisper==20231117) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/codespace/.local/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (4.12.0)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (1.12.1)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (2024.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4464e0-50dd-4287-b02b-0c382d54503e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
